{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset 2 VGG19 cross k fold",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnTRugAwPiAr",
        "outputId": "f972924a-75ef-4c31-8bd7-c02e867b8d7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l4MRfIYQESF"
      },
      "source": [
        "\n",
        "!unzip -uq \"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset2.zip\" -d \"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCn-4avQsgn",
        "outputId": "b5e3cc7e-29c2-4fde-f34e-c6c1b704f40f"
      },
      "source": [
        "# example of progressively loading images from file\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# create generator\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "img_height = 224\n",
        "img_width = 224 \n",
        "batch_size = 80\n",
        "# prepare an iterators for each dataset\n",
        "train_it = datagen.flow_from_directory('/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset2',target_size=(img_height, img_width),batch_size = batch_size, subset='training')\n",
        "#val_it = datagen.flow_from_directory('/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset2',target_size=(img_height, img_width), batch_size = batch_size, subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0NE2Yzd_WFB",
        "outputId": "36c34496-c48e-498e-b819-4444b8d3a086"
      },
      "source": [
        "from tensorflow.keras.applications import vgg19\n",
        "# Init the VGG model\n",
        "vgg_conv = vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_height, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jwVecda_f6y",
        "outputId": "9da8de4c-3a8b-47e6-f718-b9401518e5df"
      },
      "source": [
        "# Freeze all the layers\n",
        "for layer in vgg_conv.layers[:]:\n",
        "    layer.trainable = False\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fc60042f750> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f6d318d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f8d37310> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc5f8ca8990> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f88275d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f8828750> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc5f88308d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f883aa10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f883a2d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f88418d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f884c2d0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc5f8843490> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f8835dd0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f8856790> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f6d315d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f8856750> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc5f87e7250> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f6d31510> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f87e7dd0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f87f4210> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc5f87ff1d0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc5f87f4490> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQsdukGnFWAR"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "#from tensorflow.keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Embedding, Dense, Dropout, Flatten, Input,GlobalAveragePooling2D\n",
        "from keras import activations\n",
        "#from tensorflow.python.keras.layers.core import Dense, Dropout, Flatten\n",
        "#from tensorflow.python.keras.layers import Input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import LSTM\n",
        "#from keras.layers import Dropout\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications import vgg16\n",
        "from skimage.color import gray2rgb\n",
        "#from tensorflow.keras.applications.inception_v3 import InceptionV3 \n",
        "#from tensorflow.keras.applications import DenseNet201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDUAiWIeE1Ui",
        "outputId": "d98668b7-8d0d-4efc-d0fa-b0ddf45aef18"
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 45,725,770\n",
            "Trainable params: 25,701,386\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrAx1W0gGHTb",
        "outputId": "df86522a-be4a-477d-a037-5ab0bbee2c5c"
      },
      "source": [
        "train_it.samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnxc5HckGwqL"
      },
      "source": [
        "import keras\n",
        "#sgd = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV8WD7w5FZuD",
        "outputId": "94716fd5-03a9-47cb-cabe-61f6aba222f5"
      },
      "source": [
        "nb_epochs = 100\n",
        "batch_size = 128\n",
        "model.fit_generator(\n",
        "    train_it,\n",
        "    steps_per_epoch = train_it.samples // batch_size,\n",
        "    validation_data = val_it, \n",
        "    validation_steps = val_it.samples // batch_size,\n",
        "    epochs = nb_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 193s 117s/step - loss: 2.7409 - acc: 0.1024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 39s 13s/step - loss: 2.4892 - acc: 0.1198\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 2.3417 - acc: 0.1875\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 2.3479 - acc: 0.1710\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 2.3275 - acc: 0.1615\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 2.1351 - acc: 0.2300\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 2.1619 - acc: 0.2344\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 2.1253 - acc: 0.2422\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 1.9921 - acc: 0.2812\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.9537 - acc: 0.3785\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 2.0009 - acc: 0.2899\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 52s 26s/step - loss: 1.9597 - acc: 0.3438\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 39s 13s/step - loss: 1.8322 - acc: 0.4080\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.8431 - acc: 0.3663\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.7601 - acc: 0.3993\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 1.7280 - acc: 0.4792\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.7089 - acc: 0.4219\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 1.7024 - acc: 0.5443\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 52s 26s/step - loss: 1.5664 - acc: 0.5781\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 1.5648 - acc: 0.5885\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.5242 - acc: 0.6094\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 1.5782 - acc: 0.5651\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.5663 - acc: 0.5920\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.4647 - acc: 0.5851\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.4170 - acc: 0.6580\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.4082 - acc: 0.6510\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 1.4020 - acc: 0.7118\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.3484 - acc: 0.7049\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 1.3182 - acc: 0.7734\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.3473 - acc: 0.7153\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 1.2869 - acc: 0.8125\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 1.2592 - acc: 0.7882\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 1.2488 - acc: 0.7760\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 1.1827 - acc: 0.8229\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.1495 - acc: 0.8264\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.2167 - acc: 0.8281\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 1.1119 - acc: 0.8620\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.1303 - acc: 0.8715\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 1.1141 - acc: 0.8594\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.0749 - acc: 0.8194\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.0508 - acc: 0.8819\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 1.0277 - acc: 0.9132\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 1.0791 - acc: 0.8854\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 1.0072 - acc: 0.9002\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.9914 - acc: 0.8837\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.9268 - acc: 0.9167\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 0.9612 - acc: 0.9193\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.9623 - acc: 0.8984\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.9496 - acc: 0.9167\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.9529 - acc: 0.9245\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.9093 - acc: 0.9497\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 0.8979 - acc: 0.9193\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.8719 - acc: 0.9427\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.8499 - acc: 0.9297\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 39s 26s/step - loss: 0.8329 - acc: 0.9392\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.8287 - acc: 0.9392\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.7750 - acc: 0.9635\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.8387 - acc: 0.9479\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.8171 - acc: 0.9375\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.7702 - acc: 0.9410\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 0.8560 - acc: 0.9271\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.7854 - acc: 0.9401\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.7480 - acc: 0.9583\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 0.7793 - acc: 0.9583\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.7470 - acc: 0.9670\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.7619 - acc: 0.9184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.7358 - acc: 0.9288\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.7163 - acc: 0.9566\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.7202 - acc: 0.9505\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.6843 - acc: 0.9635\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 39s 26s/step - loss: 0.6961 - acc: 0.9601\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.7039 - acc: 0.9844\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.6784 - acc: 0.9505\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.6930 - acc: 0.9688\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.6387 - acc: 0.9826\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.6313 - acc: 0.9948\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.6442 - acc: 0.9792\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.5951 - acc: 0.9835\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 51s 26s/step - loss: 0.6282 - acc: 0.9583\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 0.6227 - acc: 0.9826\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.6108 - acc: 0.9965\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 0.6203 - acc: 0.9618\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.5837 - acc: 0.9826\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.5785 - acc: 0.9896\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.5789 - acc: 0.9688\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.5640 - acc: 0.9783\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.5718 - acc: 0.9896\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.5573 - acc: 0.9905\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.5695 - acc: 0.9740\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 38s 25s/step - loss: 0.5445 - acc: 0.9844\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.5039 - acc: 0.9844\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.5415 - acc: 0.9844\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.5079 - acc: 0.9878\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.5110 - acc: 0.9965\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.4902 - acc: 0.9939\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.4843 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 38s 26s/step - loss: 0.5446 - acc: 0.9792\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.4857 - acc: 0.9965\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 38s 13s/step - loss: 0.4589 - acc: 0.9818\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 51s 25s/step - loss: 0.4660 - acc: 0.9922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95b05d3c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfLx7xpSGkMO",
        "outputId": "b6a7bdfc-1c50-4eb9-e7ce-19234f57a73a"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/Dataset_2_VGG19\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/Dataset_1_VGG19/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjS87ZEc0lGu",
        "outputId": "0e14e3d3-4d98-4b00-dd8c-767e79a16f6e"
      },
      "source": [
        "val_it.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 36, 36, 36], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f7UTYKS4qKZ",
        "outputId": "ba698d83-33db-45e3-e599-cc628c471a4c"
      },
      "source": [
        "val_it.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 36, 36, 36], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lBylmDLJ2U3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af591f75-c959-4fb4-a528-d36c28109d4f"
      },
      "source": [
        "test_score = model.evaluate_generator(val_it, batch_size)\n",
        "\n",
        "\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100)) \n",
        "\n",
        "print(\"[INFO] Loss: \",test_score[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.\n",
            "[INFO] accuracy: 98.75%\n",
            "[INFO] Loss:  0.5093265771865845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkCAHjHqapxA"
      },
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D,MaxPooling2D, Activation, Dropout, BatchNormalization, Input\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSJ0iN3YasE9"
      },
      "source": [
        "#Plot the confusion matrix. Set Normalize = True/False\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    This function prints and plots the confusion matrix.\n",
        "\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.colorbar()\n",
        "\n",
        "\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        cm = np.around(cm, decimals=2)\n",
        "\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        print(\"Normalized confusion matrix\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "\n",
        "        plt.text(j, i, cm[i, j],\n",
        "\n",
        "                 horizontalalignment=\"center\",\n",
        "\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IuGHZl1at7G",
        "outputId": "a2002c36-1fb1-4764-9470-3b68f3ba4a65"
      },
      "source": [
        "#Print the Target names\n",
        "\n",
        "\n",
        "\n",
        "target_names = []\n",
        "\n",
        "for key in val_it.class_indices:\n",
        "\n",
        "    target_names.append(key)\n",
        "\n",
        "\n",
        "\n",
        "print(target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aa', 'bho', 'bishorgo', 'ga', 'la', 'po', 'rri', 'ta', 'th', 'tho']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b77T179na04N",
        "outputId": "09448b4c-2bee-4007-ab60-e6b2134dccc3"
      },
      "source": [
        "y_img_batch, y_class_batch = val_it[0]\n",
        "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
        "y_true = np.argmax(y_class_batch,-1)\n",
        "print(sum(y_pred==y_true)/batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6171875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "5Vvkwgwpa3QD",
        "outputId": "f3987870-51df-463d-9aca-0b8f7f886bb4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "plot_confusion_matrix(cm, target_names, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNR6U3Nya5Pt",
        "outputId": "26506b4e-04b0-4ee5-9565-31aa9ff45aa4"
      },
      "source": [
        "#Print Classification Report\n",
        "\n",
        "print('Classification Report')\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00         8\n",
            "           3       1.00      1.00      1.00         8\n",
            "           4       1.00      0.88      0.93         8\n",
            "           5       0.89      1.00      0.94         8\n",
            "           6       1.00      1.00      1.00         8\n",
            "           7       1.00      1.00      1.00         8\n",
            "           8       1.00      1.00      1.00         8\n",
            "           9       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si2D91iea7mu"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import keras\n",
        "num_folds = 10\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "y_img_batch, y_class_batch = train_it[0]\n",
        "verbosity = 1\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "no_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL3cWX-37Byp",
        "outputId": "949bcd6d-06c1-4e49-d3cf-cb4a6e97a963"
      },
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(y_img_batch, y_class_batch):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add the vgg convolutional base model\n",
        "  model.add(vgg_conv)\n",
        "\n",
        "  # Add new layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(y_img_batch[train], y_class_batch[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(y_img_batch[test], y_class_batch[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8117 - acc: 0.0556\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 2.4158 - acc: 0.1806\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 2.4298 - acc: 0.1528\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.2941 - acc: 0.1944\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 2.2609 - acc: 0.1944\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 2.1562 - acc: 0.2500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.2136 - acc: 0.2500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 2.1680 - acc: 0.2083\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 2.0997 - acc: 0.2222\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.1838 - acc: 0.2361\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 1.9932 - acc: 0.3333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.0428 - acc: 0.2361\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.1724 - acc: 0.1944\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 2.0734 - acc: 0.2917\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 2.0519 - acc: 0.2639\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 2.0125 - acc: 0.2917\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.9099 - acc: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 1.7918 - acc: 0.3889\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 1.9793 - acc: 0.3472\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 1.8255 - acc: 0.3472\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7441 - acc: 0.4028\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 1.8093 - acc: 0.4306\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.7968 - acc: 0.3889\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 1.8339 - acc: 0.4444\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.8098 - acc: 0.4583\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6770 - acc: 0.5139\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.6327 - acc: 0.4861\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7005 - acc: 0.5417\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6381 - acc: 0.5278\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.7176 - acc: 0.4861\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.6256 - acc: 0.5139\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5514 - acc: 0.5139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6390 - acc: 0.4583\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5860 - acc: 0.5694\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.4854 - acc: 0.6250\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.5514 - acc: 0.5556\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.4846 - acc: 0.6528\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4787 - acc: 0.6111\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.5492 - acc: 0.5972\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.4489 - acc: 0.6528\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.5244 - acc: 0.6250\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.4072 - acc: 0.6389\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3880 - acc: 0.6667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.3625 - acc: 0.6944\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.3246 - acc: 0.6944\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.3191 - acc: 0.7639\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.4257 - acc: 0.6111\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.2865 - acc: 0.7917\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.2187 - acc: 0.8611\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.2247 - acc: 0.7222\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.3238 - acc: 0.7361\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.2378 - acc: 0.8194\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2758 - acc: 0.7639\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2350 - acc: 0.7917\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.3225 - acc: 0.7639\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.2384 - acc: 0.7639\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.1842 - acc: 0.8056\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.2453 - acc: 0.7917\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1985 - acc: 0.7917\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.1158 - acc: 0.8889\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 1.2439 - acc: 0.7222\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1659 - acc: 0.8472\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 1.1840 - acc: 0.7639\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.0931 - acc: 0.8611\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 1.1920 - acc: 0.7917\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1556 - acc: 0.8472\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 1.0994 - acc: 0.8750\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 1.1168 - acc: 0.8472\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 1.0875 - acc: 0.8194\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.0528 - acc: 0.9167\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 1.1182 - acc: 0.8750\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 1.0364 - acc: 0.8889\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.1075 - acc: 0.7778\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.0984 - acc: 0.8333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 1.0077 - acc: 0.8611\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.0232 - acc: 0.8889\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 1.0209 - acc: 0.8333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 1.0386 - acc: 0.9028\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.9386 - acc: 0.9583\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.9105 - acc: 0.9167\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.9958 - acc: 0.8889\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.9680 - acc: 0.8611\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 1.0592 - acc: 0.8472\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.9629 - acc: 0.9028\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 0.9599 - acc: 0.9028\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.9344 - acc: 0.8750\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.9353 - acc: 0.9167\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9531 - acc: 0.9306\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.9211 - acc: 0.9028\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.9524 - acc: 0.9444\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.9646 - acc: 0.8472\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 0.8943 - acc: 0.9167\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.8450 - acc: 0.9306\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.8153 - acc: 0.9306\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.8632 - acc: 0.9722\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.8655 - acc: 0.9167\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.8607 - acc: 0.9028\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.8607 - acc: 0.9444\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.7960 - acc: 0.9583\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.7974 - acc: 0.9861\n",
            "Score for fold 1: loss of 0.8456449508666992; acc of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1201 - acc: 0.0139\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.4550 - acc: 0.1944\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 2.3929 - acc: 0.1250\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 2.2444 - acc: 0.1667\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 2.2919 - acc: 0.2083\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 2.2409 - acc: 0.1667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 2.1300 - acc: 0.2361\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 2.2355 - acc: 0.2083\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.0634 - acc: 0.3472\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.0603 - acc: 0.2639\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 2.1660 - acc: 0.2361\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 2.0750 - acc: 0.3056\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.8942 - acc: 0.3056\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 2.0173 - acc: 0.2917\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.8843 - acc: 0.3750\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.9513 - acc: 0.3611\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.9828 - acc: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.8395 - acc: 0.3472\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.8527 - acc: 0.4028\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.6732 - acc: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.7490 - acc: 0.4167\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.9146 - acc: 0.3472\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.7837 - acc: 0.3750\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.7471 - acc: 0.4583\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.6840 - acc: 0.4722\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.7579 - acc: 0.4444\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.5969 - acc: 0.5556\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5625 - acc: 0.5278\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.6907 - acc: 0.4861\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.6072 - acc: 0.5278\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.6388 - acc: 0.5417\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.6038 - acc: 0.5139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.5921 - acc: 0.5417\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.6053 - acc: 0.5139\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.4362 - acc: 0.6389\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4852 - acc: 0.5972\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4678 - acc: 0.5417\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4925 - acc: 0.5556\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.4030 - acc: 0.6389\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.3531 - acc: 0.7917\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.3334 - acc: 0.7500\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3599 - acc: 0.6806\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.3179 - acc: 0.7500\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.3582 - acc: 0.7639\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2975 - acc: 0.7083\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2954 - acc: 0.7778\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2836 - acc: 0.7361\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2966 - acc: 0.7222\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.3016 - acc: 0.6667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2874 - acc: 0.7778\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2451 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2513 - acc: 0.7639\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.1661 - acc: 0.8056\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.2075 - acc: 0.8611\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.2663 - acc: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.1641 - acc: 0.8194\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1977 - acc: 0.8194\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.1022 - acc: 0.8611\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1598 - acc: 0.7917\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.1412 - acc: 0.8472\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.0495 - acc: 0.9028\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1750 - acc: 0.7778\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0327 - acc: 0.9028\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.1307 - acc: 0.8056\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0870 - acc: 0.8750\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0122 - acc: 0.9306\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0779 - acc: 0.8333\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0536 - acc: 0.8611\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0023 - acc: 0.9444\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9632 - acc: 0.8750\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0681 - acc: 0.8333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0221 - acc: 0.8889\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.0083 - acc: 0.9306\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9267 - acc: 0.9444\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9985 - acc: 0.8611\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0221 - acc: 0.8750\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.9900 - acc: 0.9028\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9563 - acc: 0.9167\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0267 - acc: 0.8194\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9434 - acc: 0.9028\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9140 - acc: 0.9167\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.8939 - acc: 0.9028\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.9205 - acc: 0.8889\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.8722 - acc: 0.9722\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.8695 - acc: 0.8889\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.8614 - acc: 0.9722\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.8980 - acc: 0.9167\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.8430 - acc: 0.9306\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.8550 - acc: 0.9167\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9005 - acc: 0.8889\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8055 - acc: 0.9722\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8116 - acc: 0.9722\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.8295 - acc: 0.9028\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7866 - acc: 0.9583\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.7687 - acc: 0.9583\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.8301 - acc: 0.9306\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8152 - acc: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.8028 - acc: 0.9167\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.8100 - acc: 0.9444\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.7413 - acc: 0.9583\n",
            "Score for fold 2: loss of 1.1185274124145508; acc of 87.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8116 - acc: 0.0833\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 2.5362 - acc: 0.1111\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.5431 - acc: 0.1111\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 2.4310 - acc: 0.1528\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 2.3468 - acc: 0.2083\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 2.4232 - acc: 0.1250\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.1770 - acc: 0.1944\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.1605 - acc: 0.1806\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 2.1158 - acc: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.0949 - acc: 0.3194\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.0669 - acc: 0.2361\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.9422 - acc: 0.2917\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.9948 - acc: 0.2778\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 1.9882 - acc: 0.2778\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.9189 - acc: 0.3750\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.9214 - acc: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 1.8766 - acc: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 1.6988 - acc: 0.4861\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.9537 - acc: 0.3333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.7889 - acc: 0.3611\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7962 - acc: 0.4306\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.6785 - acc: 0.4583\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.7321 - acc: 0.4167\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.8408 - acc: 0.4306\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.6556 - acc: 0.4861\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7908 - acc: 0.3889\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.6541 - acc: 0.4167\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.7002 - acc: 0.4444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4891 - acc: 0.5694\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6583 - acc: 0.5278\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.5415 - acc: 0.5556\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.4985 - acc: 0.6111\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6102 - acc: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6057 - acc: 0.5278\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.4941 - acc: 0.6389\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.4199 - acc: 0.5694\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4639 - acc: 0.5694\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4168 - acc: 0.5972\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4323 - acc: 0.5972\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.4712 - acc: 0.6111\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4610 - acc: 0.6111\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.4793 - acc: 0.5833\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.3287 - acc: 0.7361\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3602 - acc: 0.6667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.2319 - acc: 0.7778\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.2915 - acc: 0.7222\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.3861 - acc: 0.6389\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.3159 - acc: 0.7361\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.3780 - acc: 0.6944\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 1.3423 - acc: 0.7361\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.2444 - acc: 0.7639\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 1.1775 - acc: 0.7778\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.2260 - acc: 0.7778\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.2208 - acc: 0.7361\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1510 - acc: 0.7917\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.2055 - acc: 0.7639\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2148 - acc: 0.7639\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.1819 - acc: 0.7500\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1175 - acc: 0.8611\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.1262 - acc: 0.7917\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.1383 - acc: 0.8333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0990 - acc: 0.8611\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.1200 - acc: 0.8333\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.1009 - acc: 0.8472\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0690 - acc: 0.8611\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.1280 - acc: 0.8056\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 1.0521 - acc: 0.8611\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.0997 - acc: 0.7917\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0203 - acc: 0.9167\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0478 - acc: 0.8889\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0644 - acc: 0.8333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.0363 - acc: 0.8889\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.9619 - acc: 0.9167\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9333 - acc: 0.8889\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.9209 - acc: 0.9028\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9995 - acc: 0.8194\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.9921 - acc: 0.8750\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.0184 - acc: 0.8333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9213 - acc: 0.9306\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9335 - acc: 0.9306\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.9287 - acc: 0.9028\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.8606 - acc: 0.9306\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8817 - acc: 0.9167\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8666 - acc: 0.9722\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.8563 - acc: 0.9306\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.8883 - acc: 0.9583\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9306 - acc: 0.9306\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.9302 - acc: 0.8889\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.8326 - acc: 0.9306\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8686 - acc: 0.8750\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8208 - acc: 0.9583\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8380 - acc: 0.9583\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.8365 - acc: 0.9861\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.8021 - acc: 0.9306\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8164 - acc: 0.9306\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.7824 - acc: 0.9444\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.6951 - acc: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7924 - acc: 0.9306\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.7968 - acc: 0.9583\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.7617 - acc: 0.9306\n",
            "Score for fold 3: loss of 1.2455260753631592; acc of 87.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6546 - acc: 0.0972\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.4187 - acc: 0.1111\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.3671 - acc: 0.1806\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 2.3601 - acc: 0.1389\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.2911 - acc: 0.1389\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.1979 - acc: 0.2083\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 2.1593 - acc: 0.1667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 2.3257 - acc: 0.1806\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 2.1311 - acc: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2561 - acc: 0.1528\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.9949 - acc: 0.2639\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.0245 - acc: 0.2778\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.9338 - acc: 0.3611\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 2.0162 - acc: 0.3333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.9963 - acc: 0.2500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.9122 - acc: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.8223 - acc: 0.4306\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.8586 - acc: 0.3750\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.6215 - acc: 0.4722\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7121 - acc: 0.4444\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.7651 - acc: 0.3889\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6947 - acc: 0.4722\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.7733 - acc: 0.4028\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.5616 - acc: 0.5139\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.6578 - acc: 0.5139\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.6092 - acc: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.6637 - acc: 0.5417\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.6071 - acc: 0.5417\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.6148 - acc: 0.5972\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.5537 - acc: 0.5417\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.6073 - acc: 0.5139\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5411 - acc: 0.5139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.4295 - acc: 0.6111\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.4833 - acc: 0.6389\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.5079 - acc: 0.5833\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4224 - acc: 0.6389\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.5423 - acc: 0.6111\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.3873 - acc: 0.6111\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.4603 - acc: 0.5694\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.3772 - acc: 0.7361\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.3254 - acc: 0.7222\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.3486 - acc: 0.6944\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3785 - acc: 0.6667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.3756 - acc: 0.6944\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.3687 - acc: 0.6528\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3520 - acc: 0.7083\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.2788 - acc: 0.7639\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.2596 - acc: 0.7500\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1561 - acc: 0.8194\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.2468 - acc: 0.7778\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2386 - acc: 0.7222\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1726 - acc: 0.7778\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2984 - acc: 0.6806\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1952 - acc: 0.7639\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1921 - acc: 0.8056\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.1372 - acc: 0.8194\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.2225 - acc: 0.8056\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1117 - acc: 0.8194\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.1073 - acc: 0.8472\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.0849 - acc: 0.8611\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0598 - acc: 0.8750\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.1485 - acc: 0.8333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1187 - acc: 0.8333\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0099 - acc: 0.8889\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0535 - acc: 0.9167\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.9749 - acc: 0.9028\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.9777 - acc: 0.9028\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0299 - acc: 0.8889\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9983 - acc: 0.8750\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.0744 - acc: 0.8194\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9237 - acc: 0.9028\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0151 - acc: 0.9028\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9717 - acc: 0.9028\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9124 - acc: 0.9167\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.9376 - acc: 0.8611\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9808 - acc: 0.8889\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9389 - acc: 0.9444\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8843 - acc: 0.9167\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9311 - acc: 0.9167\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9257 - acc: 0.9028\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.9069 - acc: 0.9444\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9272 - acc: 0.9167\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9393 - acc: 0.8611\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.9139 - acc: 0.9583\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9512 - acc: 0.9306\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.9020 - acc: 0.9306\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8808 - acc: 0.8889\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.8420 - acc: 0.9444\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.8214 - acc: 0.9444\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8009 - acc: 0.9028\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.9268 - acc: 0.9167\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.7978 - acc: 0.9444\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.8110 - acc: 0.9444\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.7969 - acc: 0.9444\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.7992 - acc: 0.9306\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.8074 - acc: 0.9167\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.7874 - acc: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.7334 - acc: 0.9861\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.7530 - acc: 0.9722\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.8732 - acc: 0.9444\n",
            "Score for fold 4: loss of 1.344441294670105; acc of 87.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6451 - acc: 0.0833\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 2.3938 - acc: 0.1806\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 2.5038 - acc: 0.1389\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.3878 - acc: 0.1389\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 2.2886 - acc: 0.1667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 2.3099 - acc: 0.1528\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2493 - acc: 0.2083\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.3068 - acc: 0.1944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.1672 - acc: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.2342 - acc: 0.2361\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.1176 - acc: 0.2222\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.0374 - acc: 0.2917\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.9128 - acc: 0.3750\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.9519 - acc: 0.3194\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.1575 - acc: 0.2500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.9259 - acc: 0.3750\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.8978 - acc: 0.3194\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.8084 - acc: 0.3889\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.8503 - acc: 0.3194\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.9450 - acc: 0.3333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.9435 - acc: 0.3611\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7584 - acc: 0.4028\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6925 - acc: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.8681 - acc: 0.4167\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.7559 - acc: 0.4722\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.7900 - acc: 0.3889\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.6865 - acc: 0.5556\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.6712 - acc: 0.4861\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.5989 - acc: 0.4722\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.7019 - acc: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 1.5905 - acc: 0.5972\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.4578 - acc: 0.6528\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6077 - acc: 0.5556\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5119 - acc: 0.5833\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5766 - acc: 0.6111\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.5610 - acc: 0.5417\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.5387 - acc: 0.5139\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.5844 - acc: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.5226 - acc: 0.5417\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.3816 - acc: 0.7639\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2999 - acc: 0.7500\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.4894 - acc: 0.6528\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.4540 - acc: 0.5556\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.3941 - acc: 0.6389\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3213 - acc: 0.7222\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2971 - acc: 0.7500\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.3098 - acc: 0.6944\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2676 - acc: 0.6667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.2650 - acc: 0.7500\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.2286 - acc: 0.7639\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1338 - acc: 0.8194\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.2674 - acc: 0.8056\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.2345 - acc: 0.7500\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1897 - acc: 0.7917\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.2318 - acc: 0.7222\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1328 - acc: 0.9306\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.0886 - acc: 0.7917\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.1596 - acc: 0.8194\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.1737 - acc: 0.7639\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1726 - acc: 0.7917\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.1207 - acc: 0.8750\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1678 - acc: 0.7917\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0850 - acc: 0.7778\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.1032 - acc: 0.8056\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.1302 - acc: 0.8194\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.0742 - acc: 0.8194\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.0803 - acc: 0.8056\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.0484 - acc: 0.8472\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0356 - acc: 0.8889\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.0337 - acc: 0.8611\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9954 - acc: 0.9028\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0085 - acc: 0.9306\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9936 - acc: 0.8750\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9908 - acc: 0.9167\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.9849 - acc: 0.8889\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.9161 - acc: 0.9444\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.8924 - acc: 0.9167\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.9354 - acc: 0.8889\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9463 - acc: 0.9444\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9378 - acc: 0.8889\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8971 - acc: 0.9167\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8900 - acc: 0.9444\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.8604 - acc: 0.9167\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9530 - acc: 0.8889\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9310 - acc: 0.9028\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.9087 - acc: 0.9167\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.8363 - acc: 0.9167\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.8526 - acc: 0.9444\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.8707 - acc: 0.9028\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8764 - acc: 0.9028\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8446 - acc: 0.8750\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.7843 - acc: 0.9167\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.7907 - acc: 0.9722\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8442 - acc: 0.9306\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.8024 - acc: 0.9444\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.7835 - acc: 0.9028\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.7692 - acc: 0.9306\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.7523 - acc: 0.9861\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7263 - acc: 0.9583\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.7294 - acc: 0.9444\n",
            "Score for fold 5: loss of 0.99296635389328; acc of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.6598 - acc: 0.0694\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 2.6165 - acc: 0.0278\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.4890 - acc: 0.1806\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2600 - acc: 0.1528\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.1501 - acc: 0.2222\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 2.3121 - acc: 0.1944\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 2.2187 - acc: 0.2361\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.3038 - acc: 0.1111\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.2295 - acc: 0.2639\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 2.1975 - acc: 0.2639\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 2.0935 - acc: 0.2778\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.0828 - acc: 0.3056\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.0512 - acc: 0.3056\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.9186 - acc: 0.3750\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.9442 - acc: 0.3750\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.8112 - acc: 0.4306\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.8776 - acc: 0.3611\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.8909 - acc: 0.3889\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.9005 - acc: 0.3194\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 1.8383 - acc: 0.3194\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.8071 - acc: 0.4722\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.8189 - acc: 0.3194\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.8017 - acc: 0.4306\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.7158 - acc: 0.4167\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.7336 - acc: 0.4583\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.7357 - acc: 0.3750\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.5766 - acc: 0.5417\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.7039 - acc: 0.4444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.6052 - acc: 0.5278\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5826 - acc: 0.5833\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.5320 - acc: 0.5556\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.5865 - acc: 0.5139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6575 - acc: 0.4583\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.6620 - acc: 0.4861\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.5301 - acc: 0.5833\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4111 - acc: 0.6667\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.5731 - acc: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.4745 - acc: 0.6250\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.4023 - acc: 0.6944\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.4367 - acc: 0.5556\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4445 - acc: 0.6389\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.3738 - acc: 0.7083\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3384 - acc: 0.6944\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.3274 - acc: 0.6806\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.2177 - acc: 0.7500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2816 - acc: 0.7639\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2809 - acc: 0.7778\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2884 - acc: 0.7361\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.2719 - acc: 0.7500\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.3327 - acc: 0.5833\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.2086 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.2020 - acc: 0.7500\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.2101 - acc: 0.7778\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.2070 - acc: 0.7500\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.1485 - acc: 0.7639\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2451 - acc: 0.7639\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.2447 - acc: 0.7778\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.1537 - acc: 0.8611\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.1160 - acc: 0.8750\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.1815 - acc: 0.7361\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.1029 - acc: 0.8194\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.1140 - acc: 0.8194\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0885 - acc: 0.8472\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0840 - acc: 0.8611\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0606 - acc: 0.8750\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.0833 - acc: 0.8333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0716 - acc: 0.8750\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0034 - acc: 0.9028\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.0406 - acc: 0.9028\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0134 - acc: 0.8472\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0123 - acc: 0.8611\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.9390 - acc: 0.9722\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9808 - acc: 0.9028\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0021 - acc: 0.9028\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9210 - acc: 0.8750\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9544 - acc: 0.8750\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.9585 - acc: 0.8889\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.8852 - acc: 0.9028\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9104 - acc: 0.9028\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.9321 - acc: 0.9583\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8684 - acc: 0.9028\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8418 - acc: 0.9444\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9471 - acc: 0.9306\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8262 - acc: 0.9583\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.8532 - acc: 0.9306\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8770 - acc: 0.9583\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8592 - acc: 0.9444\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.8907 - acc: 0.9028\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8345 - acc: 0.9722\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.8228 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8335 - acc: 0.9583\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8138 - acc: 0.9861\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7974 - acc: 0.9722\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.7725 - acc: 0.9167\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8266 - acc: 0.9861\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.7735 - acc: 0.9306\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.7091 - acc: 0.9861\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8103 - acc: 0.9167\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 0.7352 - acc: 0.9444\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.8071 - acc: 0.9583\n",
            "Score for fold 6: loss of 1.2742938995361328; acc of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9017 - acc: 0.0139\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 2.5130 - acc: 0.1111\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 2.3111 - acc: 0.2083\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.3681 - acc: 0.1944\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 2.1558 - acc: 0.1944\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 2.2172 - acc: 0.1806\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.1612 - acc: 0.1667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 2.2050 - acc: 0.1806\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.9884 - acc: 0.3056\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 2.1079 - acc: 0.2361\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.2142 - acc: 0.2222\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.0432 - acc: 0.3472\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.9518 - acc: 0.3056\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 2.1184 - acc: 0.2083\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 1.9122 - acc: 0.3056\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.9660 - acc: 0.3056\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 2.0006 - acc: 0.3472\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.7279 - acc: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.8937 - acc: 0.3472\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6752 - acc: 0.4861\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.8267 - acc: 0.4028\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.8368 - acc: 0.3611\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.7637 - acc: 0.4583\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.7048 - acc: 0.4722\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.7055 - acc: 0.4583\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.5576 - acc: 0.5139\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.6047 - acc: 0.5833\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.6875 - acc: 0.5139\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.6403 - acc: 0.5139\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.6175 - acc: 0.5556\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6533 - acc: 0.5278\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.6442 - acc: 0.5139\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.5234 - acc: 0.5972\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.5830 - acc: 0.6389\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.5150 - acc: 0.5833\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.4874 - acc: 0.7083\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.4592 - acc: 0.6528\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.4193 - acc: 0.6389\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4673 - acc: 0.5556\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.4093 - acc: 0.6806\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.3716 - acc: 0.6806\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.4437 - acc: 0.7222\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4315 - acc: 0.7083\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.3855 - acc: 0.7083\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.2657 - acc: 0.7500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.2995 - acc: 0.7917\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2761 - acc: 0.6806\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2417 - acc: 0.8194\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.3660 - acc: 0.6944\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3445 - acc: 0.6944\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.3660 - acc: 0.7361\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.2328 - acc: 0.8056\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.1761 - acc: 0.8194\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2232 - acc: 0.8333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1714 - acc: 0.8056\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2062 - acc: 0.8333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.1634 - acc: 0.8056\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2315 - acc: 0.7917\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1233 - acc: 0.8472\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.1604 - acc: 0.8611\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1155 - acc: 0.8750\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1048 - acc: 0.8611\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0635 - acc: 0.8472\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.0273 - acc: 0.8750\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.1105 - acc: 0.8611\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0975 - acc: 0.8333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0509 - acc: 0.8611\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0806 - acc: 0.8194\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9913 - acc: 0.9167\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.0719 - acc: 0.8611\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0818 - acc: 0.8194\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0202 - acc: 0.8750\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.9378 - acc: 0.9444\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9933 - acc: 0.8889\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9825 - acc: 0.9306\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9953 - acc: 0.9028\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.9875 - acc: 0.8472\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.9714 - acc: 0.8611\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9213 - acc: 0.9167\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9065 - acc: 0.9583\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.8823 - acc: 0.9167\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9489 - acc: 0.9167\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8943 - acc: 0.9028\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9221 - acc: 0.9444\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9740 - acc: 0.9028\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8959 - acc: 0.9028\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8408 - acc: 0.9306\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9027 - acc: 0.9167\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8394 - acc: 0.9028\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8436 - acc: 0.9167\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.7978 - acc: 0.9306\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8582 - acc: 0.9167\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.8134 - acc: 0.9306\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.8309 - acc: 0.9306\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.8165 - acc: 0.9306\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8661 - acc: 0.9028\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.8505 - acc: 0.9722\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8009 - acc: 0.9444\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7561 - acc: 0.9722\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.7840 - acc: 0.9722\n",
            "Score for fold 7: loss of 1.046918511390686; acc of 87.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7603 - acc: 0.1806\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 2.4181 - acc: 0.1806\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 2.5207 - acc: 0.0694\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 2.3751 - acc: 0.1250\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.3240 - acc: 0.1389\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2561 - acc: 0.1806\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.2568 - acc: 0.1944\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2503 - acc: 0.1111\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 2.2193 - acc: 0.2222\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 2.1982 - acc: 0.2917\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.1269 - acc: 0.2500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.1270 - acc: 0.2222\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.9706 - acc: 0.4167\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 1.9052 - acc: 0.3611\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 2.0198 - acc: 0.3333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.9896 - acc: 0.3333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.9584 - acc: 0.3333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.9423 - acc: 0.3611\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.8092 - acc: 0.3333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.7957 - acc: 0.4167\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.7305 - acc: 0.5139\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.8410 - acc: 0.3750\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.8320 - acc: 0.4167\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6708 - acc: 0.5139\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.6940 - acc: 0.4861\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.7237 - acc: 0.4167\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.6859 - acc: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.7032 - acc: 0.4444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.6556 - acc: 0.5139\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.5947 - acc: 0.4722\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5375 - acc: 0.5139\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.6557 - acc: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 1.4634 - acc: 0.6250\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5826 - acc: 0.5417\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.7144 - acc: 0.4583\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4845 - acc: 0.5833\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6053 - acc: 0.4583\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.5016 - acc: 0.5833\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4233 - acc: 0.6667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4420 - acc: 0.6250\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.5005 - acc: 0.5417\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.3830 - acc: 0.6667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.3947 - acc: 0.6528\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.3425 - acc: 0.6944\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.4058 - acc: 0.6667\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.4143 - acc: 0.6250\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3250 - acc: 0.6667\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.3886 - acc: 0.6667\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.2279 - acc: 0.7500\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 1.3264 - acc: 0.7083\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.3231 - acc: 0.6806\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.2579 - acc: 0.7361\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.2904 - acc: 0.6944\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.2819 - acc: 0.7639\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.2127 - acc: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.2223 - acc: 0.7639\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.2086 - acc: 0.8056\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.2282 - acc: 0.7917\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.2022 - acc: 0.7917\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.1373 - acc: 0.8194\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1678 - acc: 0.7361\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.1146 - acc: 0.8056\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1226 - acc: 0.7917\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.1643 - acc: 0.8056\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1068 - acc: 0.8194\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0702 - acc: 0.8194\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1000 - acc: 0.8750\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0309 - acc: 0.8750\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.1346 - acc: 0.8194\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1794 - acc: 0.7639\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.0582 - acc: 0.8472\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9909 - acc: 0.9028\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.9511 - acc: 0.9167\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 1.0260 - acc: 0.8056\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 1.0465 - acc: 0.8194\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0349 - acc: 0.8333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0181 - acc: 0.8194\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9939 - acc: 0.8750\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9088 - acc: 0.9167\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.9146 - acc: 0.9167\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9724 - acc: 0.8889\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9040 - acc: 0.9167\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8984 - acc: 0.8750\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.9091 - acc: 0.8750\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8718 - acc: 0.9306\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.9343 - acc: 0.8750\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.8720 - acc: 0.8889\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8829 - acc: 0.9167\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8695 - acc: 0.8889\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.8741 - acc: 0.9028\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.8820 - acc: 0.9028\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.7981 - acc: 0.9583\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8976 - acc: 0.9167\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.8106 - acc: 0.9028\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8921 - acc: 0.8333\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.7695 - acc: 0.9444\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.7967 - acc: 0.9028\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8095 - acc: 0.9306\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8457 - acc: 0.9444\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.7787 - acc: 0.9444\n",
            "Score for fold 8: loss of 1.2053892612457275; acc of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7130 - acc: 0.0694\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 2.6555 - acc: 0.0694\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 2.4401 - acc: 0.1250\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.3777 - acc: 0.2361\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.4070 - acc: 0.1528\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 2.4079 - acc: 0.1667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 2.2961 - acc: 0.1806\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 2.3856 - acc: 0.1528\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.2977 - acc: 0.1528\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.2791 - acc: 0.2083\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.0253 - acc: 0.3472\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 2.1790 - acc: 0.1667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 2.2017 - acc: 0.1667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.1143 - acc: 0.2222\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.0613 - acc: 0.2639\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.9914 - acc: 0.2639\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.9512 - acc: 0.3056\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.0030 - acc: 0.3333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.9436 - acc: 0.3194\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.9614 - acc: 0.3056\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.8786 - acc: 0.4444\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 1.8826 - acc: 0.3889\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.9099 - acc: 0.2639\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.8715 - acc: 0.3333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.7024 - acc: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.6908 - acc: 0.4583\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.6895 - acc: 0.4444\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6552 - acc: 0.5417\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6739 - acc: 0.4444\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.7440 - acc: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.7447 - acc: 0.4306\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.6272 - acc: 0.5278\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.6045 - acc: 0.5556\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6043 - acc: 0.5417\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.5706 - acc: 0.6250\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5430 - acc: 0.5833\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.6485 - acc: 0.4583\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.5581 - acc: 0.5556\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.5388 - acc: 0.5278\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.4519 - acc: 0.6667\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4479 - acc: 0.7083\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6067 - acc: 0.5139\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.3949 - acc: 0.6389\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.3996 - acc: 0.7361\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4066 - acc: 0.6250\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.4183 - acc: 0.6667\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.4048 - acc: 0.7222\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.4576 - acc: 0.6389\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.2739 - acc: 0.7917\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.3460 - acc: 0.6806\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.3764 - acc: 0.6528\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3571 - acc: 0.6667\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.2447 - acc: 0.7778\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.3016 - acc: 0.7361\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.3078 - acc: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.2323 - acc: 0.7500\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.1887 - acc: 0.8333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.1858 - acc: 0.8333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2767 - acc: 0.7361\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.2419 - acc: 0.7639\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1552 - acc: 0.8194\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.1617 - acc: 0.8611\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.1699 - acc: 0.8472\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 1.2369 - acc: 0.8194\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.1181 - acc: 0.8750\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.0895 - acc: 0.8889\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1243 - acc: 0.8472\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0999 - acc: 0.8056\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0930 - acc: 0.8333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.0362 - acc: 0.8889\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0406 - acc: 0.8750\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.0687 - acc: 0.8472\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.9963 - acc: 0.9167\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0805 - acc: 0.8194\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9918 - acc: 0.8889\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.0562 - acc: 0.8611\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0327 - acc: 0.9028\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.0270 - acc: 0.8611\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.0462 - acc: 0.8750\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.9741 - acc: 0.9306\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9859 - acc: 0.9444\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.9406 - acc: 0.9028\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.9176 - acc: 0.9167\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 1.0157 - acc: 0.8611\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9608 - acc: 0.9167\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9363 - acc: 0.9167\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.9235 - acc: 0.9167\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.8851 - acc: 0.8889\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.9334 - acc: 0.9583\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8883 - acc: 0.9444\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.8343 - acc: 0.9583\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9209 - acc: 0.9167\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.8704 - acc: 0.9167\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8847 - acc: 0.9306\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.8665 - acc: 0.9444\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.8524 - acc: 0.9167\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.9022 - acc: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.8241 - acc: 0.9444\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.8136 - acc: 0.9306\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.8376 - acc: 0.9306\n",
            "Score for fold 9: loss of 1.088384747505188; acc of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7973 - acc: 0.0833\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 2.4701 - acc: 0.1667\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 2.2609 - acc: 0.2222\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 2.3934 - acc: 0.1667\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.2393 - acc: 0.2500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 2.1927 - acc: 0.2083\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.3457 - acc: 0.2083\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 2.2275 - acc: 0.2083\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 2.1941 - acc: 0.1944\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 2.0971 - acc: 0.2361\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.8867 - acc: 0.3889\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 2.0710 - acc: 0.3194\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.9728 - acc: 0.3194\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.9361 - acc: 0.3889\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.9213 - acc: 0.3889\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 1.8670 - acc: 0.3611\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.8933 - acc: 0.3056\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.8028 - acc: 0.4444\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.6901 - acc: 0.5139\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.9038 - acc: 0.3889\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.7172 - acc: 0.4722\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.7373 - acc: 0.3333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.8050 - acc: 0.3750\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.6693 - acc: 0.4444\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.6588 - acc: 0.4583\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.6234 - acc: 0.4583\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.6489 - acc: 0.5417\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.5948 - acc: 0.5139\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5364 - acc: 0.5694\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.5384 - acc: 0.5417\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.5130 - acc: 0.5417\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.5026 - acc: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5367 - acc: 0.6250\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.5264 - acc: 0.5417\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 1.5977 - acc: 0.4722\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.5393 - acc: 0.5139\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.4869 - acc: 0.5833\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.4735 - acc: 0.5833\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.4048 - acc: 0.6667\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 1.4165 - acc: 0.6944\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.3732 - acc: 0.6111\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.3859 - acc: 0.7222\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.3745 - acc: 0.6944\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.3092 - acc: 0.6806\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.3325 - acc: 0.7361\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2496 - acc: 0.7639\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.3068 - acc: 0.7083\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2925 - acc: 0.6806\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.3064 - acc: 0.7222\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 1.2591 - acc: 0.7222\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.2504 - acc: 0.8194\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.3063 - acc: 0.6389\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.1641 - acc: 0.8194\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.1432 - acc: 0.8333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.2317 - acc: 0.7778\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.1864 - acc: 0.8194\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.1135 - acc: 0.8333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.2475 - acc: 0.7778\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 1.1437 - acc: 0.8056\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 1.1412 - acc: 0.7917\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.0388 - acc: 0.8889\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0754 - acc: 0.8056\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 1.1009 - acc: 0.8611\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 1.0656 - acc: 0.8333\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 1.0722 - acc: 0.8194\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.1366 - acc: 0.8333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.0396 - acc: 0.8472\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.0229 - acc: 0.8889\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 1.0499 - acc: 0.8194\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 1.0215 - acc: 0.8472\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 1.0322 - acc: 0.8611\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9709 - acc: 0.9167\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9429 - acc: 0.9306\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.9463 - acc: 0.8889\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 1.0029 - acc: 0.8611\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.9636 - acc: 0.9028\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8879 - acc: 0.9583\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.9405 - acc: 0.9306\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.8680 - acc: 0.9167\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.9465 - acc: 0.9306\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8769 - acc: 0.9444\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.9515 - acc: 0.9306\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.8905 - acc: 0.9028\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.8577 - acc: 0.9167\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.9315 - acc: 0.9028\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.8826 - acc: 0.9444\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.9249 - acc: 0.8889\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8772 - acc: 0.9167\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.8073 - acc: 0.9861\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.9147 - acc: 0.8750\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.8111 - acc: 0.9861\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.8649 - acc: 0.9306\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.8447 - acc: 0.9167\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.8390 - acc: 0.9722\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7863 - acc: 0.9444\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.7907 - acc: 0.9722\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.7634 - acc: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.7810 - acc: 0.9861\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.8279 - acc: 0.9583\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.7611 - acc: 0.9583\n",
            "Score for fold 10: loss of 1.035141944885254; acc of 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv2Y3XPT7NAw",
        "outputId": "2dd39e33-cb5d-48b6-8bb9-f847f3638f5d"
      },
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.8456449508666992 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.1185274124145508 - Accuracy: 87.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.2455260753631592 - Accuracy: 87.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.344441294670105 - Accuracy: 87.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.99296635389328 - Accuracy: 75.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 1.2742938995361328 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 1.046918511390686 - Accuracy: 87.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 1.2053892612457275 - Accuracy: 75.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 1.088384747505188 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 1.035141944885254 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 90.0 (+- 9.354143466934854)\n",
            "> Loss: 1.1197234451770783\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoLDr0Pn7P2G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}