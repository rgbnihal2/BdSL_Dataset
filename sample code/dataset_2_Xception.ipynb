{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " dataset 2 Xception",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnTRugAwPiAr",
        "outputId": "61b39118-a8d1-4cb4-9021-32dec5827e75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l4MRfIYQESF"
      },
      "source": [
        "\n",
        "!unzip -uq \"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset1.zip\" -d \"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCn-4avQsgn",
        "outputId": "03644757-86ff-4cd5-ecf5-5ded6ccab3ca"
      },
      "source": [
        "# example of progressively loading images from file\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# create generator\n",
        "datagen = ImageDataGenerator(rescale=1. / 255,validation_split=0.2)\n",
        "datagen2 = ImageDataGenerator(rescale=1. / 255)\n",
        "img_height = 299\n",
        "img_width = 299 \n",
        "batch_size = 80\n",
        "# prepare an iterators for each dataset\n",
        "train_it = datagen.flow_from_directory('/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset2',target_size=(img_height, img_width),batch_size = batch_size, subset='training')\n",
        "val_it = datagen.flow_from_directory('/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/dataset2',target_size=(img_height, img_width), batch_size = batch_size, subset='validation')\n",
        "#test_it = datagen2.flow_from_directory('/content/drive/MyDrive/Research and Project Stuffs/dataset Rafi/RESIZED_TESTING_DATA',target_size=(img_height, img_width), batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 320 images belonging to 10 classes.\n",
            "Found 80 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0NE2Yzd_WFB"
      },
      "source": [
        "from tensorflow.keras.applications import xception\n",
        "# Init the VGG model\n",
        "vgg_conv = xception.Xception(weights='imagenet', include_top=False, input_shape=(img_height, img_height, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jwVecda_f6y",
        "outputId": "3c7f2771-1a8b-4e6b-8d37-addb6c52389f"
      },
      "source": [
        "# Freeze all the layers\n",
        "for layer in vgg_conv.layers[0:84]:\n",
        "    layer.trainable = False\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f43fb2c7b10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b780d690> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b780d790> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b72c70d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b72c7650> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b72d9750> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b72e3290> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7276290> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7272c10> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b728a290> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b728abd0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b727ca10> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b72e3810> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f43b72a00d0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b726e290> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b729c610> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7236250> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7296910> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b723be50> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b72494d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7249c10> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7234c90> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b7276ed0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f43b725c310> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b722a810> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7259990> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71f0390> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71eb190> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71fa210> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71ff2d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71ffa10> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7208f50> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b7260810> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f43b7215510> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71e7b90> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7210b90> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7214c10> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7223fd0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7223e10> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7214490> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71b5250> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71bd4d0> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71a7450> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7223690> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71fa350> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b71f6250> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7214990> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7244750> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b723b210> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7253c90> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7215e50> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7285b50> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b729cad0> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b72684d0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71c9810> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7268690> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b72342d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71d0790> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71d5990> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71ccd10> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71dbe10> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71e3f90> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71cc810> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b716dc90> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b717a210> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7170050> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71cc4d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7188f50> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b718ef90> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7180a50> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b772c4d0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b719a750> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b772c550> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71a13d0> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b712c650> False\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b71a6b10> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7180b50> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b713e650> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b713e790> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71a1750> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7147c10> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7152e10> False\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b713e550> False\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71a1650> False\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7197bd0> True\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b71300d0> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7135310> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71df9d0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b71cfcd0> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7135450> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71d5c10> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7253d90> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b72e32d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b71d5ad0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b715e150> True\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7156d10> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7193250> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70e7890> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70eff90> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b71629d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70f2790> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7100610> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b70f6790> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7105610> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7112490> True\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b7108f50> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7162a90> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b711ff10> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70a7e50> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7117850> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70b19d0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70b8c50> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b70bd050> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70c79d0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70c9b10> True\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b70c7d10> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b70d8710> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70d4f90> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7073150> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7073410> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b70dcdd0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70b3d50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f43b70d1d10> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f43b70ad790> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70e2b50> True\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7f43b70d8a90> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b710c650> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b70f9050> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b70dc4d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f43b7164d90> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f43b7290890> True\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7f43b7156310> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQsdukGnFWAR"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "#from tensorflow.keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Embedding, Dense, Dropout, Flatten, Input,GlobalAveragePooling2D\n",
        "from keras import activations\n",
        "#from tensorflow.python.keras.layers.core import Dense, Dropout, Flatten\n",
        "#from tensorflow.python.keras.layers import Input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import LSTM\n",
        "#from keras.layers import Dropout\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications import vgg16\n",
        "from skimage.color import gray2rgb\n",
        "#from tensorflow.keras.applications.inception_v3 import InceptionV3 \n",
        "#from tensorflow.keras.applications import DenseNet201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDUAiWIeE1Ui"
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(768, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnxc5HckGwqL",
        "outputId": "df57907f-5c8d-4b71-95f1-b3b02ab1556f"
      },
      "source": [
        "import keras\n",
        "#sgd = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=1e-3),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV8WD7w5FZuD",
        "outputId": "df5fd9e3-95a7-40bf-809b-9d7af21f8510"
      },
      "source": [
        "nb_epochs = 35\n",
        "#batch_size = 80\n",
        "history = model.fit_generator(\n",
        "    train_it,\n",
        "    steps_per_epoch = train_it.samples // batch_size,\n",
        "    validation_data = val_it, \n",
        "    validation_steps = val_it.samples // batch_size,\n",
        "    epochs = nb_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "4/4 [==============================] - 122s 27s/step - loss: 42.3434 - acc: 0.1075 - val_loss: 119.8562 - val_acc: 0.1000\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 2.1109 - acc: 0.1812 - val_loss: 11.7918 - val_acc: 0.2875\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 1.5287 - acc: 0.4600 - val_loss: 6.7061 - val_acc: 0.3000\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.6948 - acc: 0.3667 - val_loss: 6.7471 - val_acc: 0.4625\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - 84s 22s/step - loss: 1.2393 - acc: 0.5808 - val_loss: 9.0175 - val_acc: 0.4625\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 1.2167 - acc: 0.6600 - val_loss: 43.7423 - val_acc: 0.2000\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - 84s 22s/step - loss: 2.4510 - acc: 0.5317 - val_loss: 5.9840 - val_acc: 0.5500\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.6821 - acc: 0.7779 - val_loss: 8.5914 - val_acc: 0.5250\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.4334 - acc: 0.8450 - val_loss: 2.9700 - val_acc: 0.7125\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - 84s 22s/step - loss: 0.0347 - acc: 0.9946 - val_loss: 2.3112 - val_acc: 0.7875\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.8738 - val_acc: 0.8375\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.6248 - val_acc: 0.8500\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 4.6594e-04 - acc: 1.0000 - val_loss: 1.4010 - val_acc: 0.8625\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 5.5924e-04 - acc: 1.0000 - val_loss: 1.2782 - val_acc: 0.8750\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 1.4748e-04 - acc: 1.0000 - val_loss: 1.2843 - val_acc: 0.8750\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 9.7246e-05 - acc: 1.0000 - val_loss: 1.3440 - val_acc: 0.8625\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 5.1228e-05 - acc: 1.0000 - val_loss: 1.2736 - val_acc: 0.8750\n",
            "Epoch 18/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 4.1972e-05 - acc: 1.0000 - val_loss: 1.1368 - val_acc: 0.8750\n",
            "Epoch 19/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 6.4988e-05 - acc: 1.0000 - val_loss: 1.0819 - val_acc: 0.8875\n",
            "Epoch 20/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 3.5483e-05 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.9000\n",
            "Epoch 21/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 1.3491e-05 - acc: 1.0000 - val_loss: 0.4226 - val_acc: 0.9500\n",
            "Epoch 22/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 1.5651e-05 - acc: 1.0000 - val_loss: 0.3347 - val_acc: 0.9625\n",
            "Epoch 23/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 9.6170e-06 - acc: 1.0000 - val_loss: 0.2776 - val_acc: 0.9625\n",
            "Epoch 24/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 4.7256e-06 - acc: 1.0000 - val_loss: 0.2261 - val_acc: 0.9750\n",
            "Epoch 25/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 1.3238e-05 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.9625\n",
            "Epoch 26/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 6.5445e-06 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9750\n",
            "Epoch 27/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 3.1970e-06 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9875\n",
            "Epoch 28/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 1.3789e-06 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9875\n",
            "Epoch 29/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 2.6011e-06 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9875\n",
            "Epoch 30/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 2.1673e-06 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 0.9875\n",
            "Epoch 31/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 4.7703e-07 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9875\n",
            "Epoch 32/35\n",
            "4/4 [==============================] - 83s 22s/step - loss: 9.8912e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 33/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 4.7743e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 34/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 3.7114e-07 - acc: 1.0000 - val_loss: 3.9135e-04 - val_acc: 1.0000\n",
            "Epoch 35/35\n",
            "4/4 [==============================] - 82s 22s/step - loss: 5.2089e-07 - acc: 1.0000 - val_loss: 2.0865e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5YOysId10lC",
        "outputId": "e59792c2-941b-4fde-a21b-c609dbee0989"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/Dataset_2_Xception\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Research and Project Stuffs/BdSL/Datasets/Dataset_2_Xception/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-zpFxZp0E7S"
      },
      "source": [
        "test_score = model.evaluate_generator(val_it, batch_size)\n",
        "\n",
        "\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100)) \n",
        "\n",
        "print(\"[INFO] Loss: \",test_score[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMaJdKxv0GYr"
      },
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D,MaxPooling2D, Activation, Dropout, BatchNormalization, Input\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import itertools "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZ5bABe0J87"
      },
      "source": [
        "# Loss Curves\n",
        "\n",
        "plt.figure(figsize=[8,6])\n",
        "\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "\n",
        "plt.title('Loss Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j3KfluZ0NTL"
      },
      "source": [
        "# Accuracy Curves\n",
        "\n",
        "plt.figure(figsize=[8,6])\n",
        "\n",
        "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
        "\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
        "\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dJ7PRDQ0QaT"
      },
      "source": [
        "#Plot the confusion matrix. Set Normalize = True/False\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    This function prints and plots the confusion matrix.\n",
        "\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.colorbar()\n",
        "\n",
        "\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        cm = np.around(cm, decimals=2)\n",
        "\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "\n",
        "        print(\"Normalized confusion matrix\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "\n",
        "        plt.text(j, i, cm[i, j],\n",
        "\n",
        "                 horizontalalignment=\"center\",\n",
        "\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z3MaxcC0mDG"
      },
      "source": [
        "#Print the Target names\n",
        "\n",
        "\n",
        "\n",
        "target_names = []\n",
        "\n",
        "for key in val_it.class_indices:\n",
        "\n",
        "    target_names.append(key)\n",
        "\n",
        "\n",
        "\n",
        "print(target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il6RkOwx0qHM"
      },
      "source": [
        "y_img_batch, y_class_batch = val_it[0]\n",
        "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
        "y_true = np.argmax(y_class_batch,-1)\n",
        "print(sum(y_pred==y_true)/batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlMMCHWK0yCE"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "plot_confusion_matrix(cm, target_names, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjV2ghW81xWI"
      },
      "source": [
        "#Print Classification Report\n",
        "\n",
        "print('Classification Report')\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHXK7lMw16Pl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}